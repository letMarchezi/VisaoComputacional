{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5, 4, 8, 7, 9, 3, 6], dtype=torch.float32)\n",
    "weight = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "\n",
    "# kernel size (tamanho do filtro)\n",
    "ks = len(weight)\n",
    "\n",
    "# Adiciona a dimensão do batch e do canal. Final: 1 x 1 x len(x)\n",
    "x = x.reshape(1, 1, len(x))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolução 1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape para adicionar 2 dimensões\n",
    "weight = weight.reshape(1, 1, ks)\n",
    "print(weight.shape)\n",
    "\n",
    "\n",
    "# Convolução\n",
    "\n",
    "# Caso não seja adicionado padding nos dados, o sinal diminuirá de dimensão \n",
    "# Realiza a multiplicação dos elementos e soma\n",
    "y = F.conv1d(x, weight, padding=ks//2)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[22., 37., 41., 49., 34., 33., 15.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionando bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[27., 42., 46., 54., 39., 38., 20.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.tensor([5.])\n",
    "y = F.conv1d(x, weight, padding=ks//2, bias=bias)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicando a convolução 1d com o método com camadas de convoluções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[1., 2., 3.]]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=ks, padding=ks//2, bias=False)\n",
    "# filtro está armazenado no atributo conv.weight\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = weight\n",
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[22., 37., 41., 49., 34., 33., 15.]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = conv(x)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolução pode ser implementada como um produto matricial!\n",
    "\n",
    "\n",
    "Ou seja, a convolução 1D pode ser realizada com uma camada linear:\n",
    "\n",
    "Mesmo resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22., 37., 41., 49., 34., 33., 15.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([\n",
    "    [2, 3, 0, 0, 0, 0, 0],\n",
    "    [1, 2, 3, 0, 0, 0, 0],\n",
    "    [0, 1, 2, 3, 0, 0, 0],\n",
    "    [0, 0, 1, 2, 3, 0, 0],\n",
    "    [0, 0, 0, 1, 2, 3, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 3],\n",
    "    [0, 0, 0, 0, 0, 1, 2],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "x = torch.tensor([5, 4, 8, 7, 9, 3, 6], dtype=torch.float32)\n",
    "F.linear(x, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolução com mais de um canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9806, 0.3803, 0.4162, 0.8720, 0.2542, 0.6749, 0.7670],\n",
      "         [0.6918, 0.9558, 0.9288, 0.6618, 0.2476, 0.9095, 0.1046],\n",
      "         [0.2241, 0.3956, 0.2717, 0.5412, 0.5017, 0.0506, 0.4630],\n",
      "         [0.1812, 0.6278, 0.7643, 0.6495, 0.6421, 0.8452, 0.3997]]])\n",
      "\n",
      "Canal | Quantidade de canais de entrada | tamanho dos dados\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 7])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 canal, 4 camadas e 7 imagens?\n",
    "x = torch.rand(size=(1,4,7))\n",
    "print(x)\n",
    "conv = nn.Conv1d(in_channels=4, out_channels=5, kernel_size=ks, padding=ks//2, bias=False)\n",
    "\n",
    "\n",
    "y = conv(x)\n",
    "print(\"\\nCanal | Quantidade de canais de entrada | tamanho dos dados\")\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros \n",
    "\n",
    "* O número de canais de saída $C_out$ define o numero de filtros da camada\n",
    "\n",
    "* Cada filtro possui tamanho espacial ks\n",
    "\n",
    "* Cada filtro possui profundidade (numero de canais) igual ao tensor de entrada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# [canais de saida, canal de entrada, profundidade da imagem]\n",
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4 canais e tamanho espacial 3\n",
    "conv.weight[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride\n",
    "\n",
    "O stride define o passo do filtro.\n",
    "Por exemplo, stride=2 pula de 2 em 2 elementos a cada etapa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[37., 49., 33.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5, 4, 8, 7, 9, 3, 6], dtype=torch.float32)\n",
    "weight = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "\n",
    "# kernel size (tamanho do filtro)\n",
    "ks = len(weight)\n",
    "\n",
    "# Adiciona a dimensão do batch e do canal. Final: 1 x 1 x len(x)\n",
    "x = x.reshape(1, 1, len(x))\n",
    "weight = weight.reshape(1, 1, ks)\n",
    "\n",
    "y = F.conv1d(x, weight, stride=2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride 2 pode ser utilizado para reduzir o sinal progressivamente até um tamanho desejado para utilizar na classificação da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[37., 41., 49., 34., 33.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = F.conv1d(x, weight, stride=1)\n",
    "y[0,0::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilatação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[48., 27., 44.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = F.conv1d(x, weight, dilation=2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumenta o tamanho do filtro (sem aumentar a quantidade de parâmetros) intercalando os pesos do filtro com 0. \n",
    "\n",
    "Utilizado para a tarefa **segmentação de imagens** principalmente, quando o contexto do pixel pode ser importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[48., 27., 44.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "weight_d = torch.tensor([1, 0, 2, 0, 3], dtype=torch.float32).reshape(1, 1, -1)\n",
    "F.conv1d(x, weight_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
